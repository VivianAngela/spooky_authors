{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import spacy\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test  = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled training examples: 19579\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of labelled training examples: {}\".format(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of training data for the three authors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1abce90b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADa9JREFUeJzt3WuMbXV9xvHvUw4gguF2qB6EeiBaqjUG4UTFGmNveKnR\nNxogbaq1DfbyQu0tUE2tfdNLbGltmyppMU0veLclRItWbZqgoDN4gKN4hCpVqAiYeC0vUH99sf8D\nm5Fz3TOzl/6+n2Rn1m3v9cysNfvZa609s1NVSJL6+aFlB5AkLYcFIElNWQCS1JQFIElNWQCS1JQF\nIElNWQCS1JQFIElNWQCS1NS2ZQfYn+3bt9fOnTuXHUOSvq+srq7eW1WnHGi5SRfAzp07WVlZWXYM\nSfq+kuR/DmY5TwFJUlMWgCQ1ZQFIUlMWgCQ1ZQFIUlMWgCQ1ZQFIUlMWgCQ1ZQFIUlMWgCQ1ZQFI\nUlMWgCQ1ZQFIUlMWgCQ1ZQFIUlMWgCQ1lapadoZ9yqkpXrnsFJLq9dN9ntD3SrJaVbsOtJxHAJLU\nlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUg\nSU0ddgEk+ea68Zcn+esx/AdJ7kyyO8meJC+am/7bi0WWJG2EzTwCuKyqzgZeClyRxKMNSZqQTX9S\nrqpbgG8D2zd7XZKkg7dtgfsek2T33PhJwFXrF0rydOC7wD0LrEuStMEWKYD7xikeYHYNAJj/CLLX\nJPkF4BvABVVVSQ74oEkuBi4G4PgF0kmS9muRAjiQy6rqjYd6p6q6HLgcxmcCS5I2hRdmJampZRTA\n65LcsXZbwvolSUCqpnuWJaemeOWyU0iq10/3eULfK8lqVe060HKeApKkpiwASWrKApCkpiwASWrK\nApCkpiwASWrKApCkpiwASWrKApCkpiwASWrKApCkpiwASWrKApCkpjbzA2EWdu6p57Ly+pVlx5Ck\nH0geAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVl\nAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhS\nUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSU9uWHWC/VlchWXYK\nSRuhatkJtI5HAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLUlAUgSU1ZAJLU\nlAUgSU1ZAJLU1AELIEkl+ae58W1J7klydWbuTXLimLdjLP+sueXvSXJykrOS/GeS3UluSXL55nxL\nkqSDcTBHAN8CnpzkmDH+s8CdAFVVwHXAeWPeM4FPjq8kOQv4SlV9BXgTcFlVnV1VTwT+asO+C0nS\nITvYU0DvA35uDF8EXDk376OMJ/zx9TIeWgjXjuEdwB1rd6qqmw8jryRpgxxsAbwNuDDJI4CnANfP\nzbuWBwvgacB7gdPH+DOZFQTMiuHDSd6f5DVJTlgouSRpIQdVAFV1E7CT2av/962b/QngqUmOBY6s\nqm8Cn0vyeOaOAKrqrcATgXcCzwGuS3L0+nUluTjJSpKVew7rW5IkHYxDeRfQVcAbeejpH6rq/4Bb\ngVcAN4zJ1wEvAH4Y2Du37P9W1RVV9WLg28CT16+kqi6vql1VteuUQ/lOJEmH5FAK4ArgDfs4d/9R\n4NXAx8b4x4BXAdeNC8UkeV6SI8fwY4CTGReTJUlb76ALoKruqKo37WP2tcCZPFgANwCn8eD5f4Dz\ngT1JbgSuAX6nqu469MiSpI2Q8QJ9knYltbLsEJI2xoSfa37QJFmtql0HWs6/BJakpiwASWrKApCk\npiwASWrKApCkpiwASWrKApCkpiwASWrKApCkpiwASWrKApCkpiwASWrKApCkprYtO8B+nXsurPj/\nQCVpM3gEIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS\n1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQF\nIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNWQCS1JQFIElNbVt2gP1ZXYVk\n2SkkaWtVbc16PAKQpKYsAElqygKQpKYsAElqygKQpKYsAElqygKQpKYsAElqygKQpKYsAElqygKQ\npKYsAElqygKQpKYsAElq6rALIMl3kuyeu10yN297kvuT/Oq6+9ye5OYkNyX5QJLHLBJeknT4FjkC\nuK+qzp67/fHcvJcC1wEXPcz9frKqngKsAL+3wPolSQvYrFNAFwG/BTw2yWn7WOa/gMdv0volSQew\nSAEcs+4U0AUASU4HdlTVx4F3ABfs4/4vBG5eYP2SpAUs8pGQ91XV2Q8z/QJmT/wAbwOuAP5sbv5H\nknwHuAl43fo7J7kYuHg29iMLxJMk7U/qMD98Msk3q+q4h5m+CjwGuH9MOhX48aq6NcntwK6quvfg\n1rGrZpcKJKmPRT8TOMlqVe060HIbeg0gyY8Cx1XVY6tqZ1XtBP6Ih78YLElaokVOAR2TZPfc+L8D\n9wHvXbfcu4G3A3+4wLokSRvssAugqo44yOVuAp44hnce7vokSRvLvwSWpKYsAElqygKQpKYsAElq\nygKQpKYsAElqygKQpKYsAElqygKQpKYsAElqygKQpKYsAElqygKQpKYW+XfQm+7cc2HFz4ORpE3h\nEYAkNWUBSFJTFoAkNWUBSFJTFoAkNWUBSFJTFoAkNWUBSFJTFoAkNWUBSFJTFoAkNWUBSFJTFoAk\nNWUBSFJTFoAkNWUBSFJTFoAkNZWqWnaGfUryDWDvsnPsx3bg3mWHOICpZzTf4qae0XyLO9SMj6uq\nUw600KQ/EhLYW1W7lh1iX5KsTDkfTD+j+RY39YzmW9xmZfQUkCQ1ZQFIUlNTL4DLlx3gAKaeD6af\n0XyLm3pG8y1uUzJO+iKwJGnzTP0IQJK0SSZZAEmel2RvktuSXLLF674iyd1J9sxNOynJB5PcOr6e\nOKYnyZtGzpuSnDN3n5eN5W9N8rINzHd6ko8k+XSSTyV51ZQyJnlEko8nuXHke8OYfkaS60eOtyc5\nakw/eozfNubvnHusS8f0vUmeuxH55h77iCSfTHL1RPPdnuTmJLuTrIxpk9jG43FPSPKuJJ9JckuS\n8yaW76zxs1u7fT3JqyeW8TXjd2RPkivH787W7odVNakbcATw38CZwFHAjcCTtnD9zwbOAfbMTftT\n4JIxfAnwJ2P4BcD7gQDPAK4f008CPje+njiGT9ygfDuAc8bwo4DPAk+aSsaxnuPG8JHA9WO97wAu\nHNPfDPzaGP514M1j+ELg7WP4SWPbHw2cMfaJIzZwO/8m8C/A1WN8avluB7avmzaJbTwe+x+AXxnD\nRwEnTCnfuqxHAHcBj5tKRuCxwOeBY+b2v5dv9X64oT/oDdpY5wHXzI1fCly6xRl28tAC2AvsGMM7\nmP19AsBbgIvWLwdcBLxlbvpDltvgrP8G/OwUMwKPBG4Ans7sj1i2rd/GwDXAeWN421gu67f7/HIb\nkOs04EPATwFXj/VNJt94vNv53gKYxDYGjmf25JUp5nuYvOcD104pI7MC+CKzYtk29sPnbvV+OMVT\nQGs/mDV3jGnL9Oiq+tIYvgt49BjeV9Yt+R7GYeBTmb3KnkzGcXplN3A38EFmr0q+WlXffph1PZBj\nzP8acPJm5gP+Avhd4Ltj/OSJ5QMo4ANJVpNcPKZNZRufAdwDvHWcRvu7JMdOKN96FwJXjuFJZKyq\nO4E3Al8AvsRsv1pli/fDKRbApNWsZpf+1qkkxwHvBl5dVV+fn7fsjFX1nao6m9kr7acBP7asLOsl\neSFwd1WtLjvLATyrqs4Bng/8RpJnz89c8jbexuw06d9W1VOBbzE7nfKAZe+Da8Y59BcB71w/b5kZ\nx7WHFzMr01OBY4HnbXWOKRbAncDpc+OnjWnL9OUkOwDG17vH9H1l3dTvIcmRzJ78/7mq3jPFjABV\n9VXgI8wOZU9IsvavR+bX9UCOMf944CubmO8ngBcluR14G7PTQH85oXzAA68Qqaq7gfcyK9KpbOM7\ngDuq6vox/i5mhTCVfPOeD9xQVV8e41PJ+DPA56vqnqq6H3gPs31zS/fDKRbAJ4AnjKvhRzE7fLtq\nyZmuAtau/r+M2Xn3tem/ON5B8Azga+Pw8hrg/CQnjqY/f0xbWJIAfw/cUlV/PrWMSU5JcsIYPobZ\n9YlbmBXBS/aRby33S4APj1dmVwEXjnc/nAE8Afj4ovmq6tKqOq2qdjLbtz5cVT8/lXwASY5N8qi1\nYWbbZg8T2cZVdRfwxSRnjUk/DXx6KvnWuYgHT/+sZZlCxi8Az0jyyPE7vfYz3Nr9cKMvuGzEjdkV\n+c8yO3f82i1e95XMzsndz+yVzi8zO9f2IeBW4D+Ak8ayAf5m5LwZ2DX3OK8Abhu3X9rAfM9idth6\nE7B73F4wlYzAU4BPjnx7gN8f088cO+ZtzA7Hjx7THzHGbxvzz5x7rNeO3HuB52/Ctn4OD74LaDL5\nRpYbx+1Ta78DU9nG43HPBlbGdv5XZu+QmUy+8djHMnuVfPzctMlkBN4AfGb8nvwjs3fybOl+6F8C\nS1JTUzwFJEnaAhaAJDVlAUhSUxaAJDVlAUhSUxaAJDVlAUhSUxaAJDX1/6DTjitf8uq4AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ab8e7ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Distribution of training data for the three authors\")\n",
    "train['author'].value_counts().plot(kind=\"barh\", color='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unlabelled test examples: 8392\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unlabelled test examples: {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple split for screening model performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train.author, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-fold stratified CV for robust model performance\n",
    "X = train\n",
    "y = train.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'MWS'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check for label ordering\n",
    "# 0: EAP, 1: HPL, 2: MWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    EAP\n",
       "1    HPL\n",
       "2    EAP\n",
       "3    MWS\n",
       "4    HPL\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(y)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author-specific Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_EAP = pd.read_csv('data/ner_EAP.csv', header=None)\n",
    "ner_EAP = ner_EAP[0].tolist()\n",
    "ner_HPL = pd.read_csv('data/ner_HPL.csv', header=None)\n",
    "ner_HPL = ner_HPL[0].tolist()\n",
    "ner_MWS = pd.read_csv('data/ner_MWS.csv', header=None)\n",
    "ner_MWS = ner_MWS[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Epicurus', \"Von Kempelen's\", 'Underduk', 'Ellison', 'Mein Gott']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_EAP[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_CV(clf, X, y, folds, transform=True):\n",
    "    \"\"\" Run a stratified k-fold Cross Validation on the training set and print the results.\n",
    "        \n",
    "        Args:\n",
    "            clf (Pipeline): sklearn Pipeline\n",
    "            X    (pandas df): data points, here: novel snippets\n",
    "            y    (pandas df): class labels, here: authors\n",
    "            folds      (int): number of folds\n",
    "            transform (bool): if True, use .fit_transform(); if False, use .fit()\n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    precision, recall, f1 = [], [], []\n",
    "\n",
    "    fold_cntr = 1\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if transform == True:\n",
    "            clf.fit_transform(X_train, y_train)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted = text_clf.predict(X_test)\n",
    "        prec_, rec_, f1_ = precision_recall_fscore_support(y_test, predicted, average='macro')[:3]\n",
    "        \n",
    "        precision.append(prec_)\n",
    "        recall.append(rec_)\n",
    "        f1.append(f1_)\n",
    "        \n",
    "        print(\"FOLD: {} Precision: {}, Recall: {}, F1: {}\".format(fold_cntr, round(prec_,3), round(rec_,3), round(f1_,3)))\n",
    "        fold_cntr += 1\n",
    "        \n",
    "    print(\"\\nAverage results of {}-fold stratified CV\\n\".format(folds))\n",
    "    print(\"Precision: {}, Standard deviation: {}\".format(np.mean(precision), np.std(precision)))\n",
    "    print(\"Recall:    {}, Standard deviation: {}\".format(np.mean(recall), np.std(recall)))\n",
    "    print(\"Macro f1:  {}, Standard deviation: {}\".format(np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFrameColumnExtracter(TransformerMixin):\n",
    "\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        # print([{'length': len(text), 'num_sentences': text.count('.')} for text in posts])\n",
    "        return [{'length': len(text), 'num_sentences': text.count('.')} for text in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_extractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        \"\"\"The workhorse of this feature extractor\"\"\"\n",
    "        ner_list = []\n",
    "        for text in posts:\n",
    "            doc = nlp(text)\n",
    "            eap_ners = 0\n",
    "            hpl_ners = 0\n",
    "            mws_ners = 0\n",
    "            if doc.ents:\n",
    "                for ent in doc.ents:\n",
    "                    if ent.text in ner_EAP:\n",
    "                        eap_ners += 1\n",
    "                    elif ent.text in ner_HPL:\n",
    "                        hpl_ners += 1\n",
    "                    elif ent.text in ner_MWS:\n",
    "                        mws_ners += 1\n",
    "                    \n",
    "            # print({'eap_ners':eap_ners, 'hpl_ners':hpl_ners, 'mws_ner':mws_ners})\n",
    "            ner_list.append({'eap_ners':eap_ners, 'hpl_ners':hpl_ners, 'mws_ner':mws_ners})\n",
    "        return ner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "    # Use FeatureUnion to combine the features\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text snippet\n",
    "            ('text_snipped', Pipeline([\n",
    "                ('selector', DataFrameColumnExtracter('text')),\n",
    "                ('count_vect', CountVectorizer()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling ad hoc features text snippet\n",
    "            ('text_stats', Pipeline([\n",
    "                ('selector', DataFrameColumnExtracter('text')),\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    " \n",
    "            # Pipeline for pulling NER features text snippet\n",
    "            ('text_ner', Pipeline([\n",
    "                ('selector', DataFrameColumnExtracter('text')),\n",
    "                ('stats', NER_extractor()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        #weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'text_snippet': 1.0,\n",
    "            'text_stats': 1.0,\n",
    "            'text_ner': 2.0\n",
    "        },\n",
    "    )),\n",
    "\n",
    "    # The machine learning algo , alpha=1\n",
    "    ('clf', MultinomialNB(alpha=0.05)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train#.head(500)\n",
    "y_train_sample = y_train#.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_snipped', Pipeline(steps=[('selector', <__main__.DataFrameColumnExtracter object at 0x1aad76f28>), ('count_vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encodin...: 2.0, 'text_snippet': 1.0})), ('clf', MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.83      0.86      0.84      1507\n",
      "        HPL       0.85      0.86      0.86      1055\n",
      "        MWS       0.87      0.82      0.85      1354\n",
      "\n",
      "avg / total       0.85      0.85      0.85      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_snipped', Pipeline(steps=[('selector', <__main__.DataFrameColumnExtracter object at 0x11a8f5320>), ('count_vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encodin...er': 2.0, 'text_snippet': 1.0})), ('clf', MultinomialNB(alpha=1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"bow_text_stats_ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>2.013889e-03</td>\n",
       "      <td>9.450205e-05</td>\n",
       "      <td>9.978916e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>9.999989e-01</td>\n",
       "      <td>1.085319e-06</td>\n",
       "      <td>4.892497e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>3.983234e-03</td>\n",
       "      <td>9.960149e-01</td>\n",
       "      <td>1.886647e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>4.382620e-01</td>\n",
       "      <td>5.617378e-01</td>\n",
       "      <td>2.533355e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>9.719542e-01</td>\n",
       "      <td>4.984518e-03</td>\n",
       "      <td>2.306131e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27337</th>\n",
       "      <td>9.472334e-01</td>\n",
       "      <td>5.267928e-02</td>\n",
       "      <td>8.732578e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24265</th>\n",
       "      <td>9.827260e-01</td>\n",
       "      <td>1.042980e-02</td>\n",
       "      <td>6.844222e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25917</th>\n",
       "      <td>7.111841e-04</td>\n",
       "      <td>1.542022e-03</td>\n",
       "      <td>9.977468e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04951</th>\n",
       "      <td>9.999539e-01</td>\n",
       "      <td>4.604601e-05</td>\n",
       "      <td>5.408511e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14549</th>\n",
       "      <td>9.351211e-01</td>\n",
       "      <td>8.856711e-03</td>\n",
       "      <td>5.602220e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22505</th>\n",
       "      <td>1.512678e-03</td>\n",
       "      <td>1.588631e-02</td>\n",
       "      <td>9.826010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24002</th>\n",
       "      <td>1.741599e-20</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.153971e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18982</th>\n",
       "      <td>2.495353e-02</td>\n",
       "      <td>8.621161e-02</td>\n",
       "      <td>8.888349e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15181</th>\n",
       "      <td>9.432831e-05</td>\n",
       "      <td>9.999046e-01</td>\n",
       "      <td>1.032675e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id21888</th>\n",
       "      <td>9.999935e-01</td>\n",
       "      <td>3.310109e-06</td>\n",
       "      <td>3.234244e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12035</th>\n",
       "      <td>5.948514e-05</td>\n",
       "      <td>3.303136e-06</td>\n",
       "      <td>9.999372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17991</th>\n",
       "      <td>2.824168e-01</td>\n",
       "      <td>2.121359e-03</td>\n",
       "      <td>7.154619e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10707</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.034658e-15</td>\n",
       "      <td>3.012044e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07101</th>\n",
       "      <td>2.576323e-01</td>\n",
       "      <td>2.997482e-02</td>\n",
       "      <td>7.123929e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00345</th>\n",
       "      <td>6.109467e-01</td>\n",
       "      <td>3.883045e-01</td>\n",
       "      <td>7.488064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05912</th>\n",
       "      <td>9.907931e-01</td>\n",
       "      <td>8.968566e-04</td>\n",
       "      <td>8.310051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13443</th>\n",
       "      <td>9.984252e-01</td>\n",
       "      <td>5.302005e-05</td>\n",
       "      <td>1.521782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09248</th>\n",
       "      <td>1.404861e-01</td>\n",
       "      <td>9.829772e-02</td>\n",
       "      <td>7.612161e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17542</th>\n",
       "      <td>7.816222e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.963332e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id06995</th>\n",
       "      <td>1.530840e-03</td>\n",
       "      <td>4.062695e-07</td>\n",
       "      <td>9.984688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25159</th>\n",
       "      <td>6.562559e-01</td>\n",
       "      <td>4.545098e-03</td>\n",
       "      <td>3.391990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25729</th>\n",
       "      <td>9.621712e-01</td>\n",
       "      <td>2.876724e-02</td>\n",
       "      <td>9.061561e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26949</th>\n",
       "      <td>9.916107e-01</td>\n",
       "      <td>5.632209e-03</td>\n",
       "      <td>2.757085e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27191</th>\n",
       "      <td>5.636344e-03</td>\n",
       "      <td>2.908986e-09</td>\n",
       "      <td>9.943637e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07668</th>\n",
       "      <td>1.206279e-03</td>\n",
       "      <td>5.799733e-11</td>\n",
       "      <td>9.987937e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22510</th>\n",
       "      <td>1.687813e-04</td>\n",
       "      <td>1.144860e-05</td>\n",
       "      <td>9.998198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19204</th>\n",
       "      <td>9.994332e-01</td>\n",
       "      <td>3.557966e-04</td>\n",
       "      <td>2.109846e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05758</th>\n",
       "      <td>5.270641e-03</td>\n",
       "      <td>2.109261e-02</td>\n",
       "      <td>9.736368e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27063</th>\n",
       "      <td>5.433302e-01</td>\n",
       "      <td>9.907061e-02</td>\n",
       "      <td>3.575991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11773</th>\n",
       "      <td>1.005877e-05</td>\n",
       "      <td>7.279996e-11</td>\n",
       "      <td>9.999899e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11562</th>\n",
       "      <td>8.533110e-01</td>\n",
       "      <td>2.142836e-04</td>\n",
       "      <td>1.464747e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16208</th>\n",
       "      <td>1.904795e-02</td>\n",
       "      <td>2.588248e-04</td>\n",
       "      <td>9.806932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04036</th>\n",
       "      <td>6.604118e-04</td>\n",
       "      <td>2.400410e-03</td>\n",
       "      <td>9.969392e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26159</th>\n",
       "      <td>8.826763e-01</td>\n",
       "      <td>2.320150e-06</td>\n",
       "      <td>1.173214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26777</th>\n",
       "      <td>2.890474e-01</td>\n",
       "      <td>3.241798e-01</td>\n",
       "      <td>3.867728e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08501</th>\n",
       "      <td>8.590328e-01</td>\n",
       "      <td>3.707263e-02</td>\n",
       "      <td>1.038946e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11216</th>\n",
       "      <td>9.926207e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.462573e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03410</th>\n",
       "      <td>9.210442e-01</td>\n",
       "      <td>2.034704e-02</td>\n",
       "      <td>5.860878e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04537</th>\n",
       "      <td>1.148967e-02</td>\n",
       "      <td>4.211947e-07</td>\n",
       "      <td>9.885099e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26628</th>\n",
       "      <td>9.987968e-01</td>\n",
       "      <td>8.074975e-04</td>\n",
       "      <td>3.957336e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01586</th>\n",
       "      <td>4.214772e-02</td>\n",
       "      <td>9.576926e-01</td>\n",
       "      <td>1.596357e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13421</th>\n",
       "      <td>9.370651e-02</td>\n",
       "      <td>4.442654e-02</td>\n",
       "      <td>8.618669e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26084</th>\n",
       "      <td>6.930411e-03</td>\n",
       "      <td>9.927913e-01</td>\n",
       "      <td>2.782926e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05375</th>\n",
       "      <td>7.643083e-06</td>\n",
       "      <td>5.236620e-10</td>\n",
       "      <td>9.999924e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23212</th>\n",
       "      <td>9.999201e-01</td>\n",
       "      <td>4.892850e-05</td>\n",
       "      <td>3.101714e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15980</th>\n",
       "      <td>9.302110e-01</td>\n",
       "      <td>5.010767e-02</td>\n",
       "      <td>1.968128e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11719</th>\n",
       "      <td>5.413722e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.267651e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13109</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.719981e-10</td>\n",
       "      <td>1.197452e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07156</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.031364e-08</td>\n",
       "      <td>5.525363e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04893</th>\n",
       "      <td>2.013601e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>2.905446e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11749</th>\n",
       "      <td>8.145774e-01</td>\n",
       "      <td>6.362066e-03</td>\n",
       "      <td>1.790606e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10526</th>\n",
       "      <td>1.096676e-02</td>\n",
       "      <td>1.407656e-02</td>\n",
       "      <td>9.749567e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13477</th>\n",
       "      <td>9.998856e-01</td>\n",
       "      <td>2.647108e-05</td>\n",
       "      <td>8.792249e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13761</th>\n",
       "      <td>1.597484e-03</td>\n",
       "      <td>4.762984e-07</td>\n",
       "      <td>9.984020e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04282</th>\n",
       "      <td>5.555858e-03</td>\n",
       "      <td>9.944440e-01</td>\n",
       "      <td>1.326781e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EAP           HPL           MWS\n",
       "id                                               \n",
       "id02310  2.013889e-03  9.450205e-05  9.978916e-01\n",
       "id24541  9.999989e-01  1.085319e-06  4.892497e-08\n",
       "id00134  3.983234e-03  9.960149e-01  1.886647e-06\n",
       "id27757  4.382620e-01  5.617378e-01  2.533355e-07\n",
       "id04081  9.719542e-01  4.984518e-03  2.306131e-02\n",
       "id27337  9.472334e-01  5.267928e-02  8.732578e-05\n",
       "id24265  9.827260e-01  1.042980e-02  6.844222e-03\n",
       "id25917  7.111841e-04  1.542022e-03  9.977468e-01\n",
       "id04951  9.999539e-01  4.604601e-05  5.408511e-09\n",
       "id14549  9.351211e-01  8.856711e-03  5.602220e-02\n",
       "id22505  1.512678e-03  1.588631e-02  9.826010e-01\n",
       "id24002  1.741599e-20  1.000000e+00  1.153971e-20\n",
       "id18982  2.495353e-02  8.621161e-02  8.888349e-01\n",
       "id15181  9.432831e-05  9.999046e-01  1.032675e-06\n",
       "id21888  9.999935e-01  3.310109e-06  3.234244e-06\n",
       "id12035  5.948514e-05  3.303136e-06  9.999372e-01\n",
       "id17991  2.824168e-01  2.121359e-03  7.154619e-01\n",
       "id10707  1.000000e+00  1.034658e-15  3.012044e-15\n",
       "id07101  2.576323e-01  2.997482e-02  7.123929e-01\n",
       "id00345  6.109467e-01  3.883045e-01  7.488064e-04\n",
       "id05912  9.907931e-01  8.968566e-04  8.310051e-03\n",
       "id13443  9.984252e-01  5.302005e-05  1.521782e-03\n",
       "id09248  1.404861e-01  9.829772e-02  7.612161e-01\n",
       "id17542  7.816222e-15  1.000000e+00  4.963332e-14\n",
       "id06995  1.530840e-03  4.062695e-07  9.984688e-01\n",
       "id25159  6.562559e-01  4.545098e-03  3.391990e-01\n",
       "id25729  9.621712e-01  2.876724e-02  9.061561e-03\n",
       "id26949  9.916107e-01  5.632209e-03  2.757085e-03\n",
       "id27191  5.636344e-03  2.908986e-09  9.943637e-01\n",
       "id07668  1.206279e-03  5.799733e-11  9.987937e-01\n",
       "...               ...           ...           ...\n",
       "id22510  1.687813e-04  1.144860e-05  9.998198e-01\n",
       "id19204  9.994332e-01  3.557966e-04  2.109846e-04\n",
       "id05758  5.270641e-03  2.109261e-02  9.736368e-01\n",
       "id27063  5.433302e-01  9.907061e-02  3.575991e-01\n",
       "id11773  1.005877e-05  7.279996e-11  9.999899e-01\n",
       "id11562  8.533110e-01  2.142836e-04  1.464747e-01\n",
       "id16208  1.904795e-02  2.588248e-04  9.806932e-01\n",
       "id04036  6.604118e-04  2.400410e-03  9.969392e-01\n",
       "id26159  8.826763e-01  2.320150e-06  1.173214e-01\n",
       "id26777  2.890474e-01  3.241798e-01  3.867728e-01\n",
       "id08501  8.590328e-01  3.707263e-02  1.038946e-01\n",
       "id11216  9.926207e-16  1.000000e+00  1.462573e-13\n",
       "id03410  9.210442e-01  2.034704e-02  5.860878e-02\n",
       "id04537  1.148967e-02  4.211947e-07  9.885099e-01\n",
       "id26628  9.987968e-01  8.074975e-04  3.957336e-04\n",
       "id01586  4.214772e-02  9.576926e-01  1.596357e-04\n",
       "id13421  9.370651e-02  4.442654e-02  8.618669e-01\n",
       "id26084  6.930411e-03  9.927913e-01  2.782926e-04\n",
       "id05375  7.643083e-06  5.236620e-10  9.999924e-01\n",
       "id23212  9.999201e-01  4.892850e-05  3.101714e-05\n",
       "id15980  9.302110e-01  5.010767e-02  1.968128e-02\n",
       "id11719  5.413722e-08  9.999999e-01  1.267651e-10\n",
       "id13109  1.000000e+00  1.719981e-10  1.197452e-08\n",
       "id07156  9.999999e-01  1.031364e-08  5.525363e-08\n",
       "id04893  2.013601e-07  9.999998e-01  2.905446e-09\n",
       "id11749  8.145774e-01  6.362066e-03  1.790606e-01\n",
       "id10526  1.096676e-02  1.407656e-02  9.749567e-01\n",
       "id13477  9.998856e-01  2.647108e-05  8.792249e-05\n",
       "id13761  1.597484e-03  4.762984e-07  9.984020e-01\n",
       "id04282  5.555858e-03  9.944440e-01  1.326781e-07\n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.predict_for_kaggle(clf=pipeline, X=test, columns=le.classes_, ids=test.id, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "    # Use FeatureUnion to combine the features\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text snippet\n",
    "            ('text_snipped', Pipeline([\n",
    "                ('selector', DataFrameColumnExtracter('text')),\n",
    "                ('count_vect', CountVectorizer()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling ad hoc features text snippet\n",
    "            ('text_stats', Pipeline([\n",
    "                ('selector', DataFrameColumnExtracter('text')),\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    " \n",
    "            # Pipeline for pulling NER features text snippet\n",
    "            ('text_ner', Pipeline([\n",
    "                ('selector', DataFrameColumnExtracter('text')),\n",
    "                ('stats', NER_extractor()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        #weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'text_snippet': 1.0,\n",
    "            'text_stats': 1.0,\n",
    "            'text_ner': 1.0\n",
    "        },\n",
    "    )),\n",
    "\n",
    "    # The machine learning algo\n",
    "    ('clf', LogisticRegression(C=1.0, penalty='l2', class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_snipped', Pipeline(steps=[('selector', <__main__.DataFrameColumnExtracter object at 0x114169278>), ('count_vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encodin...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84473953013278857"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.86      0.83      0.85      1637\n",
      "        HPL       0.82      0.85      0.84      1030\n",
      "        MWS       0.84      0.86      0.85      1249\n",
      "\n",
      "avg / total       0.85      0.84      0.84      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold_CV(clf=pipeline, X=X, y=y, folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10, transform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
