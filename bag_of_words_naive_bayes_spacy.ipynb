{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import spacy\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/docs/usage/models\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test  = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.nltk.org/book/ch02.html\n",
    "nltk_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPLIST = set(nltk_stopwords + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]\n",
    "\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = nlp(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    # tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train.head(1)['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'process',\n",
       " 'however',\n",
       " 'afford',\n",
       " 'me',\n",
       " 'no',\n",
       " 'means',\n",
       " 'of',\n",
       " 'ascertain',\n",
       " 'the',\n",
       " 'dimension',\n",
       " 'of',\n",
       " 'my',\n",
       " 'dungeon',\n",
       " 'as',\n",
       " 'i',\n",
       " 'may',\n",
       " 'make',\n",
       " 'its',\n",
       " 'circuit',\n",
       " 'and',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'point',\n",
       " 'whence',\n",
       " 'i',\n",
       " 'set',\n",
       " 'out',\n",
       " 'without',\n",
       " 'be',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'so',\n",
       " 'perfectly',\n",
       " 'uniform',\n",
       " 'seem',\n",
       " 'the',\n",
       " 'wall']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizeText(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled training examples: 19579\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of labelled training examples: {}\".format(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of training data for the three authors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11370e128>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1135af208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Distribution of training data for the three authors\")\n",
    "train['author'].value_counts().plot(kind=\"barh\", color='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unlabelled test examples: 8392\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unlabelled test examples: {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple split for screening model performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.text, train.author, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-fold stratified CV for robust model performance\n",
    "X = train.text\n",
    "y = train.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'MWS'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check for label ordering\n",
    "# 0: EAP, 1: HPL, 2: MWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    EAP\n",
       "1    HPL\n",
       "2    EAP\n",
       "3    MWS\n",
       "4    HPL\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(y)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_CV(clf, X, y, folds, transform=True):\n",
    "    \"\"\" Run a stratified k-fold Cross Validation on the training set and print the results.\n",
    "        \n",
    "        Args:\n",
    "            clf (Pipeline): sklearn Pipeline\n",
    "            X    (pandas df): data points, here: novel snippets\n",
    "            y    (pandas df): class labels, here: authors\n",
    "            folds      (int): number of folds\n",
    "            transform (bool): if True, use .fit_transform(); if False, use .fit()\n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    precision, recall, f1 = [], [], []\n",
    "\n",
    "    fold_cntr = 1\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if transform == True:\n",
    "            clf.fit_transform(X_train, y_train)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted = text_clf.predict(X_test)\n",
    "        prec_, rec_, f1_ = precision_recall_fscore_support(y_test, predicted, average='macro')[:3]\n",
    "        \n",
    "        precision.append(prec_)\n",
    "        recall.append(rec_)\n",
    "        f1.append(f1_)\n",
    "        \n",
    "        print(\"FOLD: {} Precision: {}, Recall: {}, F1: {}\".format(fold_cntr, round(prec_,3), round(rec_,3), round(f1_,3)))\n",
    "        fold_cntr += 1\n",
    "        \n",
    "    print(\"\\nAverage results of {}-fold stratified CV\\n\".format(folds))\n",
    "    print(\"Precision: {}\".format(np.mean(precision)))\n",
    "    print(\"Recall:    {}\".format(np.mean(recall)))\n",
    "    print(\"Macro f1:  {}\".format(np.mean(f1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(tokenizer=tokenizeText)),\n",
    "                     ('clf', MultinomialNB(alpha=0.05)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizeText at 0x1aaef29d8>, vocabulary=None)), ('clf', MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83605720122574056"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.81      0.86      0.83      1469\n",
      "        HPL       0.84      0.83      0.84      1083\n",
      "        MWS       0.87      0.81      0.84      1364\n",
      "\n",
      "avg / total       0.84      0.84      0.84      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.856, Recall: 0.859, F1: 0.857\n",
      "FOLD: 2 Precision: 0.831, Recall: 0.834, F1: 0.832\n",
      "FOLD: 3 Precision: 0.852, Recall: 0.856, F1: 0.853\n",
      "FOLD: 4 Precision: 0.834, Recall: 0.836, F1: 0.834\n",
      "FOLD: 5 Precision: 0.835, Recall: 0.839, F1: 0.836\n",
      "FOLD: 6 Precision: 0.845, Recall: 0.849, F1: 0.846\n",
      "FOLD: 7 Precision: 0.856, Recall: 0.86, F1: 0.857\n",
      "FOLD: 8 Precision: 0.854, Recall: 0.858, F1: 0.855\n",
      "FOLD: 9 Precision: 0.84, Recall: 0.841, F1: 0.841\n",
      "FOLD: 10 Precision: 0.851, Recall: 0.851, F1: 0.85\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.8453698709260064\n",
      "Recall:    0.8482562332086235\n",
      "Macro f1:  0.8462804690851018\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10, transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"naive_bayes_spacy_tokeniser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>1.900075e-05</td>\n",
       "      <td>4.800536e-06</td>\n",
       "      <td>9.999762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.871609e-08</td>\n",
       "      <td>2.298218e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>1.374318e-02</td>\n",
       "      <td>9.862568e-01</td>\n",
       "      <td>2.465973e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>1.238646e-01</td>\n",
       "      <td>8.761354e-01</td>\n",
       "      <td>3.865434e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>9.711225e-01</td>\n",
       "      <td>1.829142e-02</td>\n",
       "      <td>1.058613e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27337</th>\n",
       "      <td>4.757240e-01</td>\n",
       "      <td>5.242754e-01</td>\n",
       "      <td>5.731451e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24265</th>\n",
       "      <td>4.986457e-01</td>\n",
       "      <td>4.927780e-01</td>\n",
       "      <td>8.576264e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25917</th>\n",
       "      <td>2.757610e-04</td>\n",
       "      <td>2.046920e-04</td>\n",
       "      <td>9.995195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04951</th>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>2.891954e-07</td>\n",
       "      <td>2.563721e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14549</th>\n",
       "      <td>8.891036e-01</td>\n",
       "      <td>2.811310e-02</td>\n",
       "      <td>8.278328e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22505</th>\n",
       "      <td>1.753525e-04</td>\n",
       "      <td>2.215265e-03</td>\n",
       "      <td>9.976094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24002</th>\n",
       "      <td>2.507308e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.894761e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18982</th>\n",
       "      <td>5.595018e-01</td>\n",
       "      <td>3.482891e-01</td>\n",
       "      <td>9.220918e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15181</th>\n",
       "      <td>1.417811e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.532412e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id21888</th>\n",
       "      <td>9.646560e-01</td>\n",
       "      <td>2.112562e-02</td>\n",
       "      <td>1.421841e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12035</th>\n",
       "      <td>1.545236e-06</td>\n",
       "      <td>3.578698e-07</td>\n",
       "      <td>9.999981e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17991</th>\n",
       "      <td>2.691930e-02</td>\n",
       "      <td>6.164012e-04</td>\n",
       "      <td>9.724643e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10707</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.253098e-13</td>\n",
       "      <td>1.396118e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07101</th>\n",
       "      <td>2.847532e-02</td>\n",
       "      <td>9.845701e-02</td>\n",
       "      <td>8.730677e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00345</th>\n",
       "      <td>5.975653e-03</td>\n",
       "      <td>9.940242e-01</td>\n",
       "      <td>1.123038e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05912</th>\n",
       "      <td>9.912284e-01</td>\n",
       "      <td>2.946192e-03</td>\n",
       "      <td>5.825383e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13443</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.461588e-09</td>\n",
       "      <td>5.344761e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09248</th>\n",
       "      <td>6.374125e-03</td>\n",
       "      <td>7.715812e-03</td>\n",
       "      <td>9.859101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17542</th>\n",
       "      <td>2.889258e-05</td>\n",
       "      <td>9.999623e-01</td>\n",
       "      <td>8.830539e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id06995</th>\n",
       "      <td>1.581320e-02</td>\n",
       "      <td>8.045274e-09</td>\n",
       "      <td>9.841868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25159</th>\n",
       "      <td>9.191798e-01</td>\n",
       "      <td>2.526400e-05</td>\n",
       "      <td>8.079498e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25729</th>\n",
       "      <td>8.547848e-01</td>\n",
       "      <td>1.448652e-01</td>\n",
       "      <td>3.499975e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26949</th>\n",
       "      <td>9.955171e-01</td>\n",
       "      <td>4.373850e-03</td>\n",
       "      <td>1.090286e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27191</th>\n",
       "      <td>1.580486e-01</td>\n",
       "      <td>6.778220e-11</td>\n",
       "      <td>8.419514e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07668</th>\n",
       "      <td>2.975042e-04</td>\n",
       "      <td>1.924042e-12</td>\n",
       "      <td>9.997025e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22510</th>\n",
       "      <td>6.467603e-05</td>\n",
       "      <td>6.936836e-07</td>\n",
       "      <td>9.999346e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19204</th>\n",
       "      <td>9.997280e-01</td>\n",
       "      <td>2.370806e-04</td>\n",
       "      <td>3.488209e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05758</th>\n",
       "      <td>1.562606e-03</td>\n",
       "      <td>3.581256e-02</td>\n",
       "      <td>9.626248e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27063</th>\n",
       "      <td>9.863700e-01</td>\n",
       "      <td>8.954790e-03</td>\n",
       "      <td>4.675230e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11773</th>\n",
       "      <td>1.025677e-06</td>\n",
       "      <td>2.142581e-14</td>\n",
       "      <td>9.999990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11562</th>\n",
       "      <td>9.723979e-01</td>\n",
       "      <td>5.910062e-06</td>\n",
       "      <td>2.759616e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16208</th>\n",
       "      <td>7.637480e-03</td>\n",
       "      <td>6.617253e-06</td>\n",
       "      <td>9.923559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04036</th>\n",
       "      <td>3.643218e-03</td>\n",
       "      <td>2.429870e-02</td>\n",
       "      <td>9.720581e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26159</th>\n",
       "      <td>9.987463e-01</td>\n",
       "      <td>2.271669e-06</td>\n",
       "      <td>1.251407e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26777</th>\n",
       "      <td>9.588744e-01</td>\n",
       "      <td>3.025494e-02</td>\n",
       "      <td>1.087067e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08501</th>\n",
       "      <td>7.410533e-01</td>\n",
       "      <td>4.284611e-02</td>\n",
       "      <td>2.161006e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11216</th>\n",
       "      <td>1.535475e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.403955e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03410</th>\n",
       "      <td>9.932052e-01</td>\n",
       "      <td>2.608673e-03</td>\n",
       "      <td>4.186092e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04537</th>\n",
       "      <td>3.263746e-04</td>\n",
       "      <td>5.522661e-09</td>\n",
       "      <td>9.996736e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26628</th>\n",
       "      <td>9.991184e-01</td>\n",
       "      <td>8.814065e-04</td>\n",
       "      <td>2.232254e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01586</th>\n",
       "      <td>1.035246e-02</td>\n",
       "      <td>9.896356e-01</td>\n",
       "      <td>1.194123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13421</th>\n",
       "      <td>3.632392e-01</td>\n",
       "      <td>5.855797e-02</td>\n",
       "      <td>5.782028e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26084</th>\n",
       "      <td>2.111905e-02</td>\n",
       "      <td>9.788654e-01</td>\n",
       "      <td>1.557212e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05375</th>\n",
       "      <td>2.503517e-07</td>\n",
       "      <td>8.117471e-12</td>\n",
       "      <td>9.999997e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23212</th>\n",
       "      <td>9.999936e-01</td>\n",
       "      <td>4.560451e-06</td>\n",
       "      <td>1.839512e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15980</th>\n",
       "      <td>7.983516e-01</td>\n",
       "      <td>1.295336e-01</td>\n",
       "      <td>7.211476e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11719</th>\n",
       "      <td>1.031903e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.202237e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13109</th>\n",
       "      <td>9.999974e-01</td>\n",
       "      <td>7.570812e-07</td>\n",
       "      <td>1.796541e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07156</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.940556e-15</td>\n",
       "      <td>2.425388e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04893</th>\n",
       "      <td>8.355149e-02</td>\n",
       "      <td>9.164219e-01</td>\n",
       "      <td>2.662059e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11749</th>\n",
       "      <td>5.681957e-01</td>\n",
       "      <td>1.312824e-02</td>\n",
       "      <td>4.186761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10526</th>\n",
       "      <td>8.426777e-03</td>\n",
       "      <td>1.067469e-02</td>\n",
       "      <td>9.808985e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13477</th>\n",
       "      <td>9.999967e-01</td>\n",
       "      <td>1.249169e-06</td>\n",
       "      <td>2.001690e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13761</th>\n",
       "      <td>5.082031e-05</td>\n",
       "      <td>6.671098e-10</td>\n",
       "      <td>9.999492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04282</th>\n",
       "      <td>1.057435e-05</td>\n",
       "      <td>9.999894e-01</td>\n",
       "      <td>8.024676e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EAP           HPL           MWS\n",
       "id                                               \n",
       "id02310  1.900075e-05  4.800536e-06  9.999762e-01\n",
       "id24541  1.000000e+00  4.871609e-08  2.298218e-11\n",
       "id00134  1.374318e-02  9.862568e-01  2.465973e-08\n",
       "id27757  1.238646e-01  8.761354e-01  3.865434e-13\n",
       "id04081  9.711225e-01  1.829142e-02  1.058613e-02\n",
       "id27337  4.757240e-01  5.242754e-01  5.731451e-07\n",
       "id24265  4.986457e-01  4.927780e-01  8.576264e-03\n",
       "id25917  2.757610e-04  2.046920e-04  9.995195e-01\n",
       "id04951  9.999997e-01  2.891954e-07  2.563721e-16\n",
       "id14549  8.891036e-01  2.811310e-02  8.278328e-02\n",
       "id22505  1.753525e-04  2.215265e-03  9.976094e-01\n",
       "id24002  2.507308e-17  1.000000e+00  2.894761e-16\n",
       "id18982  5.595018e-01  3.482891e-01  9.220918e-02\n",
       "id15181  1.417811e-08  1.000000e+00  5.532412e-12\n",
       "id21888  9.646560e-01  2.112562e-02  1.421841e-02\n",
       "id12035  1.545236e-06  3.578698e-07  9.999981e-01\n",
       "id17991  2.691930e-02  6.164012e-04  9.724643e-01\n",
       "id10707  1.000000e+00  7.253098e-13  1.396118e-13\n",
       "id07101  2.847532e-02  9.845701e-02  8.730677e-01\n",
       "id00345  5.975653e-03  9.940242e-01  1.123038e-07\n",
       "id05912  9.912284e-01  2.946192e-03  5.825383e-03\n",
       "id13443  1.000000e+00  3.461588e-09  5.344761e-11\n",
       "id09248  6.374125e-03  7.715812e-03  9.859101e-01\n",
       "id17542  2.889258e-05  9.999623e-01  8.830539e-06\n",
       "id06995  1.581320e-02  8.045274e-09  9.841868e-01\n",
       "id25159  9.191798e-01  2.526400e-05  8.079498e-02\n",
       "id25729  8.547848e-01  1.448652e-01  3.499975e-04\n",
       "id26949  9.955171e-01  4.373850e-03  1.090286e-04\n",
       "id27191  1.580486e-01  6.778220e-11  8.419514e-01\n",
       "id07668  2.975042e-04  1.924042e-12  9.997025e-01\n",
       "...               ...           ...           ...\n",
       "id22510  6.467603e-05  6.936836e-07  9.999346e-01\n",
       "id19204  9.997280e-01  2.370806e-04  3.488209e-05\n",
       "id05758  1.562606e-03  3.581256e-02  9.626248e-01\n",
       "id27063  9.863700e-01  8.954790e-03  4.675230e-03\n",
       "id11773  1.025677e-06  2.142581e-14  9.999990e-01\n",
       "id11562  9.723979e-01  5.910062e-06  2.759616e-02\n",
       "id16208  7.637480e-03  6.617253e-06  9.923559e-01\n",
       "id04036  3.643218e-03  2.429870e-02  9.720581e-01\n",
       "id26159  9.987463e-01  2.271669e-06  1.251407e-03\n",
       "id26777  9.588744e-01  3.025494e-02  1.087067e-02\n",
       "id08501  7.410533e-01  4.284611e-02  2.161006e-01\n",
       "id11216  1.535475e-15  1.000000e+00  9.403955e-14\n",
       "id03410  9.932052e-01  2.608673e-03  4.186092e-03\n",
       "id04537  3.263746e-04  5.522661e-09  9.996736e-01\n",
       "id26628  9.991184e-01  8.814065e-04  2.232254e-07\n",
       "id01586  1.035246e-02  9.896356e-01  1.194123e-05\n",
       "id13421  3.632392e-01  5.855797e-02  5.782028e-01\n",
       "id26084  2.111905e-02  9.788654e-01  1.557212e-05\n",
       "id05375  2.503517e-07  8.117471e-12  9.999997e-01\n",
       "id23212  9.999936e-01  4.560451e-06  1.839512e-06\n",
       "id15980  7.983516e-01  1.295336e-01  7.211476e-02\n",
       "id11719  1.031903e-11  1.000000e+00  3.202237e-16\n",
       "id13109  9.999974e-01  7.570812e-07  1.796541e-06\n",
       "id07156  1.000000e+00  1.940556e-15  2.425388e-12\n",
       "id04893  8.355149e-02  9.164219e-01  2.662059e-05\n",
       "id11749  5.681957e-01  1.312824e-02  4.186761e-01\n",
       "id10526  8.426777e-03  1.067469e-02  9.808985e-01\n",
       "id13477  9.999967e-01  1.249169e-06  2.001690e-06\n",
       "id13761  5.082031e-05  6.671098e-10  9.999492e-01\n",
       "id04282  1.057435e-05  9.999894e-01  8.024676e-16\n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.predict_for_kaggle(clf=text_clf, X=test.text, columns=le.classes_, ids=test.id, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LogisticRegression(C=1.0, penalty='l2', class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
