{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test  = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled training examples: 19579\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of labelled training examples: {}\".format(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of training data for the three authors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x110bfdba8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110bfd278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Distribution of training data for the three authors\")\n",
    "train['author'].value_counts().plot(kind=\"barh\", color='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unlabelled test examples: 8392\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unlabelled test examples: {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple split for screening model performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.text, train.author, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-fold stratified CV for robust model performance\n",
    "X = train.text\n",
    "y = train.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'MWS'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check for label ordering\n",
    "# 0: EAP, 1: HPL, 2: MWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    EAP\n",
       "1    HPL\n",
       "2    EAP\n",
       "3    MWS\n",
       "4    HPL\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(y)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV(clf, X, y, folds, transform=True):\n",
    "    \"\"\" Run a stratified k-fold Cross Validation on the training set and print the results.\n",
    "        \n",
    "        Args:\n",
    "            clf (Pipeline): sklearn Pipeline\n",
    "            X    (pandas df): data points, here: novel snippets\n",
    "            y    (pandas df): class labels, here: authors\n",
    "            folds      (int): number of folds\n",
    "            transform (bool): if True, use .fit_transform(); if False, use .fit()\n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    precision, recall, f1 = [], [], []\n",
    "\n",
    "    fold_cntr = 1\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if transform == True:\n",
    "            clf.fit_transform(X_train, y_train)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted = text_clf.predict(X_test)\n",
    "        prec_, rec_, f1_ = precision_recall_fscore_support(y_test, predicted, average='macro')[:3]\n",
    "        \n",
    "        precision.append(prec_)\n",
    "        recall.append(rec_)\n",
    "        f1.append(f1_)\n",
    "        \n",
    "        print(\"FOLD: {} Precision: {}, Recall: {}, F1: {}\".format(fold_cntr, round(prec_,3), round(rec_,3), round(f1_,3)))\n",
    "        fold_cntr += 1\n",
    "        \n",
    "    print(\"\\nAverage results of {}-fold stratified CV\\n\".format(folds))\n",
    "    print(\"Precision: {}\".format(np.mean(precision)))\n",
    "    print(\"Recall:    {}\".format(np.mean(recall)))\n",
    "    print(\"Macro f1:  {}\".format(np.mean(f1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LogisticRegression(C=1.0, penalty='l2', class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82737487231869256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.85      0.81      0.83      1645\n",
      "        HPL       0.80      0.83      0.82      1037\n",
      "        MWS       0.82      0.84      0.83      1234\n",
      "\n",
      "avg / total       0.83      0.83      0.83      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.831, Recall: 0.825, F1: 0.828\n",
      "FOLD: 2 Precision: 0.851, Recall: 0.844, F1: 0.847\n",
      "FOLD: 3 Precision: 0.842, Recall: 0.83, F1: 0.835\n",
      "FOLD: 4 Precision: 0.842, Recall: 0.839, F1: 0.84\n",
      "FOLD: 5 Precision: 0.817, Recall: 0.812, F1: 0.814\n",
      "FOLD: 6 Precision: 0.825, Recall: 0.819, F1: 0.822\n",
      "FOLD: 7 Precision: 0.83, Recall: 0.823, F1: 0.826\n",
      "FOLD: 8 Precision: 0.839, Recall: 0.835, F1: 0.837\n",
      "FOLD: 9 Precision: 0.811, Recall: 0.807, F1: 0.809\n",
      "FOLD: 10 Precision: 0.824, Recall: 0.816, F1: 0.819\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.8310135572921068\n",
      "Recall:    0.8249875064561089\n",
      "Macro f1:  0.8275421042706579\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83375893769152198"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.82      0.84      0.83      1532\n",
      "        HPL       0.81      0.85      0.83      1024\n",
      "        MWS       0.87      0.81      0.84      1360\n",
      "\n",
      "avg / total       0.83      0.83      0.83      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.845, Recall: 0.842, F1: 0.843\n",
      "FOLD: 2 Precision: 0.854, Recall: 0.852, F1: 0.852\n",
      "FOLD: 3 Precision: 0.85, Recall: 0.85, F1: 0.85\n",
      "FOLD: 4 Precision: 0.83, Recall: 0.829, F1: 0.829\n",
      "FOLD: 5 Precision: 0.858, Recall: 0.857, F1: 0.857\n",
      "FOLD: 6 Precision: 0.851, Recall: 0.853, F1: 0.851\n",
      "FOLD: 7 Precision: 0.858, Recall: 0.861, F1: 0.859\n",
      "FOLD: 8 Precision: 0.841, Recall: 0.843, F1: 0.841\n",
      "FOLD: 9 Precision: 0.838, Recall: 0.836, F1: 0.836\n",
      "FOLD: 10 Precision: 0.833, Recall: 0.831, F1: 0.831\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.8457918659707137\n",
      "Recall:    0.8453000887462874\n",
      "Macro f1:  0.8448902983792317\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10, transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"baseline_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>2.860308e-03</td>\n",
       "      <td>1.328208e-04</td>\n",
       "      <td>9.970069e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>9.999976e-01</td>\n",
       "      <td>2.351500e-06</td>\n",
       "      <td>8.010017e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>7.303461e-04</td>\n",
       "      <td>9.992676e-01</td>\n",
       "      <td>2.055840e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>8.963387e-02</td>\n",
       "      <td>9.103658e-01</td>\n",
       "      <td>3.048349e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>9.641773e-01</td>\n",
       "      <td>6.426618e-03</td>\n",
       "      <td>2.939608e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27337</th>\n",
       "      <td>8.518433e-01</td>\n",
       "      <td>1.480406e-01</td>\n",
       "      <td>1.160179e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24265</th>\n",
       "      <td>9.798258e-01</td>\n",
       "      <td>1.301714e-02</td>\n",
       "      <td>7.157082e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25917</th>\n",
       "      <td>5.211607e-04</td>\n",
       "      <td>2.141883e-03</td>\n",
       "      <td>9.973370e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04951</th>\n",
       "      <td>9.999717e-01</td>\n",
       "      <td>2.831029e-05</td>\n",
       "      <td>7.834237e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14549</th>\n",
       "      <td>9.261835e-01</td>\n",
       "      <td>1.051848e-02</td>\n",
       "      <td>6.329804e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22505</th>\n",
       "      <td>3.428916e-04</td>\n",
       "      <td>3.124135e-02</td>\n",
       "      <td>9.684158e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24002</th>\n",
       "      <td>6.359660e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.696177e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18982</th>\n",
       "      <td>1.612948e-02</td>\n",
       "      <td>1.331613e-01</td>\n",
       "      <td>8.507092e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15181</th>\n",
       "      <td>5.839620e-05</td>\n",
       "      <td>9.999411e-01</td>\n",
       "      <td>4.842684e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id21888</th>\n",
       "      <td>7.321936e-01</td>\n",
       "      <td>1.208998e-01</td>\n",
       "      <td>1.469066e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12035</th>\n",
       "      <td>6.301346e-05</td>\n",
       "      <td>4.928841e-06</td>\n",
       "      <td>9.999321e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17991</th>\n",
       "      <td>3.913840e-01</td>\n",
       "      <td>3.121805e-03</td>\n",
       "      <td>6.054942e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10707</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.207295e-10</td>\n",
       "      <td>1.458862e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07101</th>\n",
       "      <td>2.965183e-01</td>\n",
       "      <td>3.996046e-02</td>\n",
       "      <td>6.635213e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00345</th>\n",
       "      <td>7.583906e-01</td>\n",
       "      <td>2.408024e-01</td>\n",
       "      <td>8.070344e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05912</th>\n",
       "      <td>9.903783e-01</td>\n",
       "      <td>1.142912e-03</td>\n",
       "      <td>8.478743e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13443</th>\n",
       "      <td>9.959356e-01</td>\n",
       "      <td>4.156106e-04</td>\n",
       "      <td>3.648838e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09248</th>\n",
       "      <td>1.392830e-01</td>\n",
       "      <td>1.308604e-01</td>\n",
       "      <td>7.298566e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17542</th>\n",
       "      <td>1.738406e-02</td>\n",
       "      <td>9.667119e-01</td>\n",
       "      <td>1.590408e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id06995</th>\n",
       "      <td>2.235935e-03</td>\n",
       "      <td>8.900746e-07</td>\n",
       "      <td>9.977632e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25159</th>\n",
       "      <td>6.036477e-01</td>\n",
       "      <td>3.522916e-03</td>\n",
       "      <td>3.928294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25729</th>\n",
       "      <td>9.609362e-01</td>\n",
       "      <td>3.485009e-02</td>\n",
       "      <td>4.213751e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26949</th>\n",
       "      <td>9.906107e-01</td>\n",
       "      <td>6.477081e-03</td>\n",
       "      <td>2.912259e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27191</th>\n",
       "      <td>4.227675e-03</td>\n",
       "      <td>3.456662e-09</td>\n",
       "      <td>9.957723e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07668</th>\n",
       "      <td>1.870938e-03</td>\n",
       "      <td>5.315447e-11</td>\n",
       "      <td>9.981291e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22510</th>\n",
       "      <td>2.060403e-04</td>\n",
       "      <td>9.619418e-06</td>\n",
       "      <td>9.997843e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19204</th>\n",
       "      <td>9.993264e-01</td>\n",
       "      <td>3.595960e-04</td>\n",
       "      <td>3.139834e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05758</th>\n",
       "      <td>9.544405e-03</td>\n",
       "      <td>3.600165e-02</td>\n",
       "      <td>9.544539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27063</th>\n",
       "      <td>5.530840e-01</td>\n",
       "      <td>9.924412e-02</td>\n",
       "      <td>3.476719e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11773</th>\n",
       "      <td>1.021386e-05</td>\n",
       "      <td>1.209763e-10</td>\n",
       "      <td>9.999898e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11562</th>\n",
       "      <td>6.996589e-01</td>\n",
       "      <td>3.842720e-04</td>\n",
       "      <td>2.999568e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16208</th>\n",
       "      <td>1.347697e-02</td>\n",
       "      <td>4.710141e-04</td>\n",
       "      <td>9.860520e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04036</th>\n",
       "      <td>9.757882e-04</td>\n",
       "      <td>9.183295e-03</td>\n",
       "      <td>9.898409e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26159</th>\n",
       "      <td>9.724900e-01</td>\n",
       "      <td>5.191421e-06</td>\n",
       "      <td>2.750479e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26777</th>\n",
       "      <td>2.532343e-01</td>\n",
       "      <td>3.749757e-01</td>\n",
       "      <td>3.717900e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08501</th>\n",
       "      <td>8.693408e-01</td>\n",
       "      <td>4.854526e-02</td>\n",
       "      <td>8.211394e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11216</th>\n",
       "      <td>1.894374e-09</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.703156e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03410</th>\n",
       "      <td>9.389409e-01</td>\n",
       "      <td>2.226202e-02</td>\n",
       "      <td>3.879711e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04537</th>\n",
       "      <td>1.678706e-02</td>\n",
       "      <td>4.102336e-07</td>\n",
       "      <td>9.832125e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26628</th>\n",
       "      <td>9.990286e-01</td>\n",
       "      <td>5.419526e-04</td>\n",
       "      <td>4.294023e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01586</th>\n",
       "      <td>3.366848e-02</td>\n",
       "      <td>9.662128e-01</td>\n",
       "      <td>1.187518e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13421</th>\n",
       "      <td>5.979149e-02</td>\n",
       "      <td>5.390807e-02</td>\n",
       "      <td>8.863004e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26084</th>\n",
       "      <td>4.775302e-03</td>\n",
       "      <td>9.949024e-01</td>\n",
       "      <td>3.222620e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05375</th>\n",
       "      <td>7.154843e-06</td>\n",
       "      <td>1.191893e-09</td>\n",
       "      <td>9.999928e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23212</th>\n",
       "      <td>9.999310e-01</td>\n",
       "      <td>4.001603e-05</td>\n",
       "      <td>2.900593e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15980</th>\n",
       "      <td>9.072805e-01</td>\n",
       "      <td>6.917930e-02</td>\n",
       "      <td>2.354022e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11719</th>\n",
       "      <td>7.158848e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.133636e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13109</th>\n",
       "      <td>9.971264e-01</td>\n",
       "      <td>3.201784e-05</td>\n",
       "      <td>2.841629e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07156</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>4.352967e-08</td>\n",
       "      <td>3.974081e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04893</th>\n",
       "      <td>1.028627e-01</td>\n",
       "      <td>8.968761e-01</td>\n",
       "      <td>2.612862e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11749</th>\n",
       "      <td>7.878286e-01</td>\n",
       "      <td>7.965249e-03</td>\n",
       "      <td>2.042061e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10526</th>\n",
       "      <td>9.296842e-03</td>\n",
       "      <td>1.399537e-02</td>\n",
       "      <td>9.767078e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13477</th>\n",
       "      <td>9.998588e-01</td>\n",
       "      <td>4.203982e-05</td>\n",
       "      <td>9.917937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13761</th>\n",
       "      <td>4.845043e-03</td>\n",
       "      <td>1.172254e-06</td>\n",
       "      <td>9.951538e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04282</th>\n",
       "      <td>1.915079e-03</td>\n",
       "      <td>9.980849e-01</td>\n",
       "      <td>4.079200e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EAP           HPL           MWS\n",
       "id                                               \n",
       "id02310  2.860308e-03  1.328208e-04  9.970069e-01\n",
       "id24541  9.999976e-01  2.351500e-06  8.010017e-08\n",
       "id00134  7.303461e-04  9.992676e-01  2.055840e-06\n",
       "id27757  8.963387e-02  9.103658e-01  3.048349e-07\n",
       "id04081  9.641773e-01  6.426618e-03  2.939608e-02\n",
       "id27337  8.518433e-01  1.480406e-01  1.160179e-04\n",
       "id24265  9.798258e-01  1.301714e-02  7.157082e-03\n",
       "id25917  5.211607e-04  2.141883e-03  9.973370e-01\n",
       "id04951  9.999717e-01  2.831029e-05  7.834237e-09\n",
       "id14549  9.261835e-01  1.051848e-02  6.329804e-02\n",
       "id22505  3.428916e-04  3.124135e-02  9.684158e-01\n",
       "id24002  6.359660e-08  9.999999e-01  3.696177e-09\n",
       "id18982  1.612948e-02  1.331613e-01  8.507092e-01\n",
       "id15181  5.839620e-05  9.999411e-01  4.842684e-07\n",
       "id21888  7.321936e-01  1.208998e-01  1.469066e-01\n",
       "id12035  6.301346e-05  4.928841e-06  9.999321e-01\n",
       "id17991  3.913840e-01  3.121805e-03  6.054942e-01\n",
       "id10707  1.000000e+00  1.207295e-10  1.458862e-10\n",
       "id07101  2.965183e-01  3.996046e-02  6.635213e-01\n",
       "id00345  7.583906e-01  2.408024e-01  8.070344e-04\n",
       "id05912  9.903783e-01  1.142912e-03  8.478743e-03\n",
       "id13443  9.959356e-01  4.156106e-04  3.648838e-03\n",
       "id09248  1.392830e-01  1.308604e-01  7.298566e-01\n",
       "id17542  1.738406e-02  9.667119e-01  1.590408e-02\n",
       "id06995  2.235935e-03  8.900746e-07  9.977632e-01\n",
       "id25159  6.036477e-01  3.522916e-03  3.928294e-01\n",
       "id25729  9.609362e-01  3.485009e-02  4.213751e-03\n",
       "id26949  9.906107e-01  6.477081e-03  2.912259e-03\n",
       "id27191  4.227675e-03  3.456662e-09  9.957723e-01\n",
       "id07668  1.870938e-03  5.315447e-11  9.981291e-01\n",
       "...               ...           ...           ...\n",
       "id22510  2.060403e-04  9.619418e-06  9.997843e-01\n",
       "id19204  9.993264e-01  3.595960e-04  3.139834e-04\n",
       "id05758  9.544405e-03  3.600165e-02  9.544539e-01\n",
       "id27063  5.530840e-01  9.924412e-02  3.476719e-01\n",
       "id11773  1.021386e-05  1.209763e-10  9.999898e-01\n",
       "id11562  6.996589e-01  3.842720e-04  2.999568e-01\n",
       "id16208  1.347697e-02  4.710141e-04  9.860520e-01\n",
       "id04036  9.757882e-04  9.183295e-03  9.898409e-01\n",
       "id26159  9.724900e-01  5.191421e-06  2.750479e-02\n",
       "id26777  2.532343e-01  3.749757e-01  3.717900e-01\n",
       "id08501  8.693408e-01  4.854526e-02  8.211394e-02\n",
       "id11216  1.894374e-09  9.999999e-01  6.703156e-08\n",
       "id03410  9.389409e-01  2.226202e-02  3.879711e-02\n",
       "id04537  1.678706e-02  4.102336e-07  9.832125e-01\n",
       "id26628  9.990286e-01  5.419526e-04  4.294023e-04\n",
       "id01586  3.366848e-02  9.662128e-01  1.187518e-04\n",
       "id13421  5.979149e-02  5.390807e-02  8.863004e-01\n",
       "id26084  4.775302e-03  9.949024e-01  3.222620e-04\n",
       "id05375  7.154843e-06  1.191893e-09  9.999928e-01\n",
       "id23212  9.999310e-01  4.001603e-05  2.900593e-05\n",
       "id15980  9.072805e-01  6.917930e-02  2.354022e-02\n",
       "id11719  7.158848e-08  9.999999e-01  3.133636e-11\n",
       "id13109  9.971264e-01  3.201784e-05  2.841629e-03\n",
       "id07156  9.999999e-01  4.352967e-08  3.974081e-08\n",
       "id04893  1.028627e-01  8.968761e-01  2.612862e-04\n",
       "id11749  7.878286e-01  7.965249e-03  2.042061e-01\n",
       "id10526  9.296842e-03  1.399537e-02  9.767078e-01\n",
       "id13477  9.998588e-01  4.203982e-05  9.917937e-05\n",
       "id13761  4.845043e-03  1.172254e-06  9.951538e-01\n",
       "id04282  1.915079e-03  9.980849e-01  4.079200e-08\n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.predict_for_kaggle(clf=text_clf, X=test.text, columns=le.classes_, ids=test.id, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80132788559754853"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.84      0.78      0.81      1693\n",
      "        HPL       0.79      0.80      0.80      1058\n",
      "        MWS       0.76      0.84      0.80      1165\n",
      "\n",
      "avg / total       0.80      0.80      0.80      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.8, Recall: 0.789, F1: 0.793\n",
      "FOLD: 2 Precision: 0.814, Recall: 0.809, F1: 0.811\n",
      "FOLD: 3 Precision: 0.795, Recall: 0.798, F1: 0.794\n",
      "FOLD: 4 Precision: 0.812, Recall: 0.8, F1: 0.804\n",
      "FOLD: 5 Precision: 0.826, Recall: 0.806, F1: 0.813\n",
      "FOLD: 6 Precision: 0.809, Recall: 0.786, F1: 0.79\n",
      "FOLD: 7 Precision: 0.809, Recall: 0.786, F1: 0.792\n",
      "FOLD: 8 Precision: 0.81, Recall: 0.803, F1: 0.803\n",
      "FOLD: 9 Precision: 0.79, Recall: 0.79, F1: 0.786\n",
      "FOLD: 10 Precision: 0.822, Recall: 0.82, F1: 0.821\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.8086954629895194\n",
      "Recall:    0.7986685245785008\n",
      "Macro f1:  0.8006054776124021\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
