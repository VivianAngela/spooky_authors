{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test  = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled training examples: 19579\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of labelled training examples: {}\".format(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of training data for the three authors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1168f9dd8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168f9588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Distribution of training data for the three authors\")\n",
    "train['author'].value_counts().plot(kind=\"barh\", color='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unlabelled test examples: 8392\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unlabelled test examples: {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple split for screening model performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.text, train.author, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-fold stratified CV for robust model performance\n",
    "X = train.text\n",
    "y = train.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EAP', 'HPL', 'MWS'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check for label ordering\n",
    "# 0: EAP, 1: HPL, 2: MWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    EAP\n",
       "1    HPL\n",
       "2    EAP\n",
       "3    MWS\n",
       "4    HPL\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(y)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_CV(clf, X, y, folds, transform=True):\n",
    "    \"\"\" Run a stratified k-fold Cross Validation on the training set and print the results.\n",
    "        \n",
    "        Args:\n",
    "            clf (Pipeline): sklearn Pipeline\n",
    "            X    (pandas df): data points, here: novel snippets\n",
    "            y    (pandas df): class labels, here: authors\n",
    "            folds      (int): number of folds\n",
    "            transform (bool): if True, use .fit_transform(); if False, use .fit()\n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    precision, recall, f1 = [], [], []\n",
    "\n",
    "    fold_cntr = 1\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if transform == True:\n",
    "            clf.fit_transform(X_train, y_train)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicted = text_clf.predict(X_test)\n",
    "        prec_, rec_, f1_ = precision_recall_fscore_support(y_test, predicted, average='macro')[:3]\n",
    "        \n",
    "        precision.append(prec_)\n",
    "        recall.append(rec_)\n",
    "        f1.append(f1_)\n",
    "        \n",
    "        print(\"FOLD: {} Precision: {}, Recall: {}, F1: {}\".format(fold_cntr, round(prec_,3), round(rec_,3), round(f1_,3)))\n",
    "        fold_cntr += 1\n",
    "        \n",
    "    print(\"\\nAverage results of {}-fold stratified CV\\n\".format(folds))\n",
    "    print(\"Precision: {}, Standard deviation: {}\".format(np.mean(precision), np.std(precision)))\n",
    "    print(\"Recall:    {}, Standard deviation: {}\".format(np.mean(recall), np.std(recall)))\n",
    "    print(\"Macro f1:  {}, Standard deviation: {}\".format(np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LogisticRegression(C=1.0, penalty='l2', class_weight='balanced')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82737487231869256"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.85      0.81      0.83      1645\n",
      "        HPL       0.80      0.83      0.82      1037\n",
      "        MWS       0.82      0.84      0.83      1234\n",
      "\n",
      "avg / total       0.83      0.83      0.83      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.835, Recall: 0.828, F1: 0.831\n",
      "FOLD: 2 Precision: 0.832, Recall: 0.825, F1: 0.828\n",
      "FOLD: 3 Precision: 0.815, Recall: 0.81, F1: 0.812\n",
      "FOLD: 4 Precision: 0.831, Recall: 0.826, F1: 0.828\n",
      "FOLD: 5 Precision: 0.838, Recall: 0.834, F1: 0.835\n",
      "FOLD: 6 Precision: 0.834, Recall: 0.827, F1: 0.83\n",
      "FOLD: 7 Precision: 0.844, Recall: 0.836, F1: 0.839\n",
      "FOLD: 8 Precision: 0.83, Recall: 0.825, F1: 0.827\n",
      "FOLD: 9 Precision: 0.838, Recall: 0.831, F1: 0.834\n",
      "FOLD: 10 Precision: 0.83, Recall: 0.826, F1: 0.828\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.8327202045213452, Standard deviation: 0.0071148314866154964\n",
      "Recall:    0.8269225910688011, Standard deviation: 0.006698272602426866\n",
      "Macro f1:  0.8293355755974892, Standard deviation: 0.006845894699023899\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83375893769152198"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.82      0.84      0.83      1532\n",
      "        HPL       0.81      0.85      0.83      1024\n",
      "        MWS       0.87      0.81      0.84      1360\n",
      "\n",
      "avg / total       0.83      0.83      0.83      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.844, Recall: 0.841, F1: 0.842\n",
      "FOLD: 2 Precision: 0.853, Recall: 0.854, F1: 0.853\n",
      "FOLD: 3 Precision: 0.838, Recall: 0.836, F1: 0.836\n",
      "FOLD: 4 Precision: 0.847, Recall: 0.849, F1: 0.848\n",
      "FOLD: 5 Precision: 0.838, Recall: 0.837, F1: 0.836\n",
      "FOLD: 6 Precision: 0.843, Recall: 0.84, F1: 0.841\n",
      "FOLD: 7 Precision: 0.841, Recall: 0.839, F1: 0.839\n",
      "FOLD: 8 Precision: 0.852, Recall: 0.85, F1: 0.851\n",
      "FOLD: 9 Precision: 0.865, Recall: 0.862, F1: 0.862\n",
      "FOLD: 10 Precision: 0.838, Recall: 0.838, F1: 0.837\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.8458337822067576, Standard deviation: 0.008204266770652842\n",
      "Recall:    0.8447720502255471, Standard deviation: 0.008247687296600774\n",
      "Macro f1:  0.8446014765667513, Standard deviation: 0.008268558137450612\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10, transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"baseline_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>3.013316e-03</td>\n",
       "      <td>1.797291e-04</td>\n",
       "      <td>9.968070e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>9.999947e-01</td>\n",
       "      <td>5.158223e-06</td>\n",
       "      <td>1.062187e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>4.775989e-03</td>\n",
       "      <td>9.952202e-01</td>\n",
       "      <td>3.784022e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>4.351039e-01</td>\n",
       "      <td>5.648960e-01</td>\n",
       "      <td>1.823274e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>9.626553e-01</td>\n",
       "      <td>7.404530e-03</td>\n",
       "      <td>2.994018e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27337</th>\n",
       "      <td>9.295024e-01</td>\n",
       "      <td>7.041833e-02</td>\n",
       "      <td>7.922729e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24265</th>\n",
       "      <td>9.859088e-01</td>\n",
       "      <td>8.606992e-03</td>\n",
       "      <td>5.484237e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25917</th>\n",
       "      <td>2.546009e-04</td>\n",
       "      <td>7.878901e-04</td>\n",
       "      <td>9.989575e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04951</th>\n",
       "      <td>9.998365e-01</td>\n",
       "      <td>1.635120e-04</td>\n",
       "      <td>1.097967e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14549</th>\n",
       "      <td>9.112123e-01</td>\n",
       "      <td>1.031963e-02</td>\n",
       "      <td>7.846812e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22505</th>\n",
       "      <td>2.233360e-03</td>\n",
       "      <td>4.843529e-03</td>\n",
       "      <td>9.929231e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24002</th>\n",
       "      <td>5.454591e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.019142e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18982</th>\n",
       "      <td>1.770847e-02</td>\n",
       "      <td>9.808734e-02</td>\n",
       "      <td>8.842042e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15181</th>\n",
       "      <td>8.682053e-05</td>\n",
       "      <td>9.999120e-01</td>\n",
       "      <td>1.175328e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id21888</th>\n",
       "      <td>7.004619e-01</td>\n",
       "      <td>1.066183e-01</td>\n",
       "      <td>1.929198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12035</th>\n",
       "      <td>4.904590e-05</td>\n",
       "      <td>3.245869e-06</td>\n",
       "      <td>9.999477e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17991</th>\n",
       "      <td>4.915737e-01</td>\n",
       "      <td>5.831168e-03</td>\n",
       "      <td>5.025951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10707</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.524101e-10</td>\n",
       "      <td>3.567325e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07101</th>\n",
       "      <td>2.587986e-01</td>\n",
       "      <td>5.769306e-02</td>\n",
       "      <td>6.835084e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00345</th>\n",
       "      <td>4.717519e-01</td>\n",
       "      <td>5.275561e-01</td>\n",
       "      <td>6.919766e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05912</th>\n",
       "      <td>9.876306e-01</td>\n",
       "      <td>1.639768e-03</td>\n",
       "      <td>1.072966e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13443</th>\n",
       "      <td>9.988446e-01</td>\n",
       "      <td>6.973072e-05</td>\n",
       "      <td>1.085711e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09248</th>\n",
       "      <td>1.266582e-01</td>\n",
       "      <td>1.265540e-01</td>\n",
       "      <td>7.467878e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17542</th>\n",
       "      <td>1.382722e-02</td>\n",
       "      <td>9.732317e-01</td>\n",
       "      <td>1.294110e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id06995</th>\n",
       "      <td>8.932546e-04</td>\n",
       "      <td>6.224485e-07</td>\n",
       "      <td>9.991061e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25159</th>\n",
       "      <td>5.931467e-01</td>\n",
       "      <td>6.924705e-03</td>\n",
       "      <td>3.999286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25729</th>\n",
       "      <td>9.334442e-01</td>\n",
       "      <td>5.515811e-02</td>\n",
       "      <td>1.139766e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26949</th>\n",
       "      <td>9.898297e-01</td>\n",
       "      <td>8.693257e-03</td>\n",
       "      <td>1.477045e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27191</th>\n",
       "      <td>2.296395e-03</td>\n",
       "      <td>2.261528e-09</td>\n",
       "      <td>9.977036e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07668</th>\n",
       "      <td>3.760409e-03</td>\n",
       "      <td>1.185124e-10</td>\n",
       "      <td>9.962396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22510</th>\n",
       "      <td>1.916025e-04</td>\n",
       "      <td>2.118408e-05</td>\n",
       "      <td>9.997872e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19204</th>\n",
       "      <td>9.992107e-01</td>\n",
       "      <td>5.052189e-04</td>\n",
       "      <td>2.841064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05758</th>\n",
       "      <td>3.731500e-03</td>\n",
       "      <td>1.813916e-02</td>\n",
       "      <td>9.781293e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27063</th>\n",
       "      <td>5.775702e-01</td>\n",
       "      <td>1.148302e-01</td>\n",
       "      <td>3.075996e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11773</th>\n",
       "      <td>1.224288e-05</td>\n",
       "      <td>4.113330e-10</td>\n",
       "      <td>9.999878e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11562</th>\n",
       "      <td>8.427488e-01</td>\n",
       "      <td>2.943600e-04</td>\n",
       "      <td>1.569568e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16208</th>\n",
       "      <td>2.238511e-02</td>\n",
       "      <td>7.248852e-04</td>\n",
       "      <td>9.768900e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04036</th>\n",
       "      <td>1.729064e-03</td>\n",
       "      <td>8.835733e-03</td>\n",
       "      <td>9.894352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26159</th>\n",
       "      <td>8.427188e-01</td>\n",
       "      <td>5.926221e-06</td>\n",
       "      <td>1.572753e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26777</th>\n",
       "      <td>3.053925e-01</td>\n",
       "      <td>3.135270e-01</td>\n",
       "      <td>3.810805e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08501</th>\n",
       "      <td>8.270657e-01</td>\n",
       "      <td>5.078628e-02</td>\n",
       "      <td>1.221480e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11216</th>\n",
       "      <td>1.460814e-09</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>5.839743e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03410</th>\n",
       "      <td>9.249543e-01</td>\n",
       "      <td>1.864388e-02</td>\n",
       "      <td>5.640182e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04537</th>\n",
       "      <td>1.307156e-02</td>\n",
       "      <td>7.794627e-07</td>\n",
       "      <td>9.869277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26628</th>\n",
       "      <td>9.980703e-01</td>\n",
       "      <td>1.476961e-03</td>\n",
       "      <td>4.527556e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01586</th>\n",
       "      <td>4.482863e-02</td>\n",
       "      <td>9.548738e-01</td>\n",
       "      <td>2.976182e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13421</th>\n",
       "      <td>9.021772e-02</td>\n",
       "      <td>4.405208e-02</td>\n",
       "      <td>8.657302e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26084</th>\n",
       "      <td>9.326849e-03</td>\n",
       "      <td>9.903172e-01</td>\n",
       "      <td>3.559259e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05375</th>\n",
       "      <td>8.120437e-06</td>\n",
       "      <td>1.299842e-09</td>\n",
       "      <td>9.999919e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23212</th>\n",
       "      <td>9.998490e-01</td>\n",
       "      <td>9.515291e-05</td>\n",
       "      <td>5.589583e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id15980</th>\n",
       "      <td>9.084176e-01</td>\n",
       "      <td>6.747375e-02</td>\n",
       "      <td>2.410861e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11719</th>\n",
       "      <td>4.394831e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.530876e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13109</th>\n",
       "      <td>9.977421e-01</td>\n",
       "      <td>1.197955e-05</td>\n",
       "      <td>2.245900e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07156</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.436074e-08</td>\n",
       "      <td>5.106748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04893</th>\n",
       "      <td>8.958158e-02</td>\n",
       "      <td>9.098352e-01</td>\n",
       "      <td>5.832113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11749</th>\n",
       "      <td>7.922756e-01</td>\n",
       "      <td>7.908481e-03</td>\n",
       "      <td>1.998159e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10526</th>\n",
       "      <td>8.457959e-03</td>\n",
       "      <td>1.577920e-02</td>\n",
       "      <td>9.757628e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13477</th>\n",
       "      <td>9.979770e-01</td>\n",
       "      <td>6.053809e-04</td>\n",
       "      <td>1.417639e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13761</th>\n",
       "      <td>1.006619e-03</td>\n",
       "      <td>1.141640e-06</td>\n",
       "      <td>9.989922e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04282</th>\n",
       "      <td>3.430347e-03</td>\n",
       "      <td>9.965695e-01</td>\n",
       "      <td>1.361057e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EAP           HPL           MWS\n",
       "id                                               \n",
       "id02310  3.013316e-03  1.797291e-04  9.968070e-01\n",
       "id24541  9.999947e-01  5.158223e-06  1.062187e-07\n",
       "id00134  4.775989e-03  9.952202e-01  3.784022e-06\n",
       "id27757  4.351039e-01  5.648960e-01  1.823274e-07\n",
       "id04081  9.626553e-01  7.404530e-03  2.994018e-02\n",
       "id27337  9.295024e-01  7.041833e-02  7.922729e-05\n",
       "id24265  9.859088e-01  8.606992e-03  5.484237e-03\n",
       "id25917  2.546009e-04  7.878901e-04  9.989575e-01\n",
       "id04951  9.998365e-01  1.635120e-04  1.097967e-08\n",
       "id14549  9.112123e-01  1.031963e-02  7.846812e-02\n",
       "id22505  2.233360e-03  4.843529e-03  9.929231e-01\n",
       "id24002  5.454591e-08  9.999999e-01  3.019142e-09\n",
       "id18982  1.770847e-02  9.808734e-02  8.842042e-01\n",
       "id15181  8.682053e-05  9.999120e-01  1.175328e-06\n",
       "id21888  7.004619e-01  1.066183e-01  1.929198e-01\n",
       "id12035  4.904590e-05  3.245869e-06  9.999477e-01\n",
       "id17991  4.915737e-01  5.831168e-03  5.025951e-01\n",
       "id10707  1.000000e+00  1.524101e-10  3.567325e-10\n",
       "id07101  2.587986e-01  5.769306e-02  6.835084e-01\n",
       "id00345  4.717519e-01  5.275561e-01  6.919766e-04\n",
       "id05912  9.876306e-01  1.639768e-03  1.072966e-02\n",
       "id13443  9.988446e-01  6.973072e-05  1.085711e-03\n",
       "id09248  1.266582e-01  1.265540e-01  7.467878e-01\n",
       "id17542  1.382722e-02  9.732317e-01  1.294110e-02\n",
       "id06995  8.932546e-04  6.224485e-07  9.991061e-01\n",
       "id25159  5.931467e-01  6.924705e-03  3.999286e-01\n",
       "id25729  9.334442e-01  5.515811e-02  1.139766e-02\n",
       "id26949  9.898297e-01  8.693257e-03  1.477045e-03\n",
       "id27191  2.296395e-03  2.261528e-09  9.977036e-01\n",
       "id07668  3.760409e-03  1.185124e-10  9.962396e-01\n",
       "...               ...           ...           ...\n",
       "id22510  1.916025e-04  2.118408e-05  9.997872e-01\n",
       "id19204  9.992107e-01  5.052189e-04  2.841064e-04\n",
       "id05758  3.731500e-03  1.813916e-02  9.781293e-01\n",
       "id27063  5.775702e-01  1.148302e-01  3.075996e-01\n",
       "id11773  1.224288e-05  4.113330e-10  9.999878e-01\n",
       "id11562  8.427488e-01  2.943600e-04  1.569568e-01\n",
       "id16208  2.238511e-02  7.248852e-04  9.768900e-01\n",
       "id04036  1.729064e-03  8.835733e-03  9.894352e-01\n",
       "id26159  8.427188e-01  5.926221e-06  1.572753e-01\n",
       "id26777  3.053925e-01  3.135270e-01  3.810805e-01\n",
       "id08501  8.270657e-01  5.078628e-02  1.221480e-01\n",
       "id11216  1.460814e-09  9.999999e-01  5.839743e-08\n",
       "id03410  9.249543e-01  1.864388e-02  5.640182e-02\n",
       "id04537  1.307156e-02  7.794627e-07  9.869277e-01\n",
       "id26628  9.980703e-01  1.476961e-03  4.527556e-04\n",
       "id01586  4.482863e-02  9.548738e-01  2.976182e-04\n",
       "id13421  9.021772e-02  4.405208e-02  8.657302e-01\n",
       "id26084  9.326849e-03  9.903172e-01  3.559259e-04\n",
       "id05375  8.120437e-06  1.299842e-09  9.999919e-01\n",
       "id23212  9.998490e-01  9.515291e-05  5.589583e-05\n",
       "id15980  9.084176e-01  6.747375e-02  2.410861e-02\n",
       "id11719  4.394831e-08  1.000000e+00  1.530876e-10\n",
       "id13109  9.977421e-01  1.197955e-05  2.245900e-03\n",
       "id07156  9.999999e-01  1.436074e-08  5.106748e-08\n",
       "id04893  8.958158e-02  9.098352e-01  5.832113e-04\n",
       "id11749  7.922756e-01  7.908481e-03  1.998159e-01\n",
       "id10526  8.457959e-03  1.577920e-02  9.757628e-01\n",
       "id13477  9.979770e-01  6.053809e-04  1.417639e-03\n",
       "id13761  1.006619e-03  1.141640e-06  9.989922e-01\n",
       "id04282  3.430347e-03  9.965695e-01  1.361057e-07\n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.predict_for_kaggle(clf=text_clf, X=test.text, columns=le.classes_, ids=test.id, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79111338100102147"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.80      0.80      0.80      1581\n",
      "        HPL       0.73      0.84      0.78       935\n",
      "        MWS       0.83      0.76      0.79      1400\n",
      "\n",
      "avg / total       0.79      0.79      0.79      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 1 Precision: 0.818, Recall: 0.818, F1: 0.817\n",
      "FOLD: 2 Precision: 0.821, Recall: 0.819, F1: 0.819\n",
      "FOLD: 3 Precision: 0.824, Recall: 0.812, F1: 0.815\n",
      "FOLD: 4 Precision: 0.807, Recall: 0.8, F1: 0.801\n",
      "FOLD: 5 Precision: 0.814, Recall: 0.805, F1: 0.808\n",
      "FOLD: 6 Precision: 0.795, Recall: 0.788, F1: 0.79\n",
      "FOLD: 7 Precision: 0.782, Recall: 0.785, F1: 0.782\n",
      "FOLD: 8 Precision: 0.808, Recall: 0.782, F1: 0.785\n",
      "FOLD: 9 Precision: 0.801, Recall: 0.794, F1: 0.793\n",
      "FOLD: 10 Precision: 0.817, Recall: 0.801, F1: 0.806\n",
      "\n",
      "Average results of 10-fold stratified CV\n",
      "\n",
      "Precision: 0.808638759330829, Standard deviation: 0.012268274253728605\n",
      "Recall:    0.8003968891964384, Standard deviation: 0.012700073648492181\n",
      "Macro f1:  0.8017314280632434, Standard deviation: 0.01277753724096159\n"
     ]
    }
   ],
   "source": [
    "kfold_CV(clf=text_clf, X=X, y=y, folds=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
